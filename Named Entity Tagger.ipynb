{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset conll2003 (C:\\Users\\anton\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee)\n",
      "100%|██████████| 3/3 [00:00<00:00, 144.09it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].set_format(type='tensorflow', columns=['tokens', 'ner_tags'])\n",
    "dataset['test'].set_format(type='tensorflow', columns=['tokens', 'ner_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((dataset['train']['tokens'], dataset['train']['ner_tags']))\n",
    "val_set = tf.data.Dataset.from_tensor_slices((dataset['test']['tokens'], dataset['test']['ner_tags']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dataset['train']['tokens']\n",
    "vectors = tf.keras.layers.StringLookup()\n",
    "\n",
    "vectors.adapt(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset_builder\n",
    "dataset_builder = load_dataset_builder('conll2003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = dataset_builder.info.features['ner_tags'].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\AppData\\Local\\Programs\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.5.0 and strictly below 2.8.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from layers import Transformer\n",
    "from training import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(512,256,2048,0.1,2,vocab = vectors, num_class= len(tags)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 in 2.4 seconds --- Training loss: 980.16278 --- Validation loss: 1728.6676 --- F1-Score: 0.09\n",
      "Epoch: 1 in 0.1 seconds --- Training loss: 1958.81421 --- Validation loss: 444.97232 --- F1-Score: 0.1\n",
      "Epoch: 2 in 0.1 seconds --- Training loss: 365.56717 --- Validation loss: 559.06384 --- F1-Score: 0.09\n",
      "Epoch: 3 in 0.1 seconds --- Training loss: 482.10736 --- Validation loss: 531.38904 --- F1-Score: 0.09\n",
      "Epoch: 4 in 0.1 seconds --- Training loss: 434.3562 --- Validation loss: 467.88837 --- F1-Score: 0.09\n",
      "Epoch: 5 in 0.1 seconds --- Training loss: 352.7196 --- Validation loss: 393.6933 --- F1-Score: 0.15\n",
      "Epoch: 6 in 0.1 seconds --- Training loss: 282.99301 --- Validation loss: 345.70239 --- F1-Score: 0.21\n",
      "Epoch: 7 in 0.1 seconds --- Training loss: 256.38464 --- Validation loss: 327.0784 --- F1-Score: 0.24\n",
      "Epoch: 8 in 0.1 seconds --- Training loss: 220.48824 --- Validation loss: 320.91724 --- F1-Score: 0.22\n",
      "Epoch: 9 in 0.1 seconds --- Training loss: 193.96387 --- Validation loss: 292.35056 --- F1-Score: 0.24\n",
      "Epoch: 10 in 0.1 seconds --- Training loss: 151.15077 --- Validation loss: 277.03674 --- F1-Score: 0.36\n",
      "Epoch: 11 in 0.1 seconds --- Training loss: 92.53171 --- Validation loss: 285.66394 --- F1-Score: 0.52\n",
      "Epoch: 12 in 0.1 seconds --- Training loss: 112.49126 --- Validation loss: 349.8241 --- F1-Score: 0.63\n",
      "Epoch: 13 in 0.1 seconds --- Training loss: 83.31229 --- Validation loss: 375.39929 --- F1-Score: 0.49\n",
      "Epoch: 14 in 0.1 seconds --- Training loss: 77.40577 --- Validation loss: 366.29947 --- F1-Score: 0.53\n",
      "Epoch: 15 in 0.1 seconds --- Training loss: 58.97894 --- Validation loss: 347.55255 --- F1-Score: 0.61\n",
      "Epoch: 16 in 0.1 seconds --- Training loss: 50.1501 --- Validation loss: 348.61917 --- F1-Score: 0.61\n",
      "Epoch: 17 in 0.1 seconds --- Training loss: 32.2847 --- Validation loss: 346.71027 --- F1-Score: 0.68\n",
      "Epoch: 18 in 0.1 seconds --- Training loss: 15.27516 --- Validation loss: 376.10571 --- F1-Score: 0.74\n",
      "Epoch: 19 in 0.1 seconds --- Training loss: 12.08725 --- Validation loss: 403.06091 --- F1-Score: 0.71\n"
     ]
    }
   ],
   "source": [
    "train(train_set, val_set, model = model, batch_size= 16, epochs = 20, num_class=len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da95418060c73b87ae5c62a1c3126f5b833663ac65c720b414713112550375bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
